---
title: "Breast Cancer Prediction Report"
author: "Akansha Vashisth, Talha Siddiqui"
date: "2018/11/24"
output: github_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
knitr::opts_knit$set(root.dir = here::here())
```

```{r libraries, message=FALSE, include=FALSE}
library(tidyverse)
```

```{r read_data, message=FALSE, include=FALSE}
data = read_csv(here::here("results/detailed.csv"))

predictors <- data %>% select(-Classification, -Predictions, -Type)
```


## Introduction

Breast Cancer Predictions analysis aims to identify the strongest predictors of breast cancer. The question that it attempts to answer is as follows:

> What are the strongest predictors of breast cancer?

The analysis is built on the anthropometric data and parameters of 64 patients with breast cancer and 52 healthy controls collected by the Faculty of Medicine of the University of Coimbra and the University Hospital Centre of Coimbra. Identifying the strongest predictors of breast cancer in information that can be gathered in a routine blood analysis is hugely beneficial.

## Data Set

The data comprises of nine predictors, and a binary dependent variable indicating the presence or absence of breast cancer. All nine predictors are quantitative variables with positive values. A summary of data set is as follows:

```{r data_summary, echo=FALSE}
knitr::kable(do.call(cbind, lapply(predictors, summary)))
```

Table 1. Summary of data set

A visual distribution of each predictor separated by breast cancer patients and healthy controls is as follows:

```{r eda_plots, echo=FALSE, fig.width=10.5, fig.height=10.5}
pngs = lapply(sprintf(here::here("img/plot%i.png"), 1:9), png::readPNG)
gl = lapply(pngs, grid::rasterGrob)
gridExtra::grid.arrange(grobs=gl)
```

Figure 1. Distribution of predictors separated by classification

## Analysis

The analysis to identify the strongest predictors is best addressed using a decision tree classification algorithm. This algorithm is parametric, which allows it to assess all the features and complete training data to pick the strongest predictors. Other supervised learning approaches that are non-parametric such as K-Nearest Neighbours would not be able to rank the predictors by their importance.

The configuration of the decision tree classifier algorithm was optimized for this analysis by the process of cross-validation. In this process, different values of maximum tree depth and minimum samples split were tested on a subset of the data and the optimum values were used to carry out the predictions. The accuracy of the predictions on training and test data are as follows:

```{r echo=FALSE, fig.width=3, fig.height=4}
data %>% 
  mutate(Acc = Classification==Predictions) %>% 
  group_by(Type) %>% 
  summarise(Accuracy = sum(Acc)/n()) %>% 
  ggplot(aes(x = Type, y = Accuracy, fill = Accuracy)) + geom_col() + theme_bw() +
  theme(legend.position = "none")
```

Figure 2. Training and test accuracy

## Results

The result of the analysis indicates that Glucose, Resistin and Age are the strongest indicators of breast cancer. The complete list of parameters which are important in predicting breast cancer are as follows:

![strongest-predictors](../img/results.png)

Figure 3. Predictors of breast cancer

The analysis suggests that Glucose levels are around 36%, Resistin 22% and Age 12% indicative of breast cancer. The predictors that are not indicative of breast cancer are HOMA and Insulin.

## Critique

### Limitations

The primary limitation of the analysis is limited data. The model is trained on 80% of the total data which is only 92 examples. That is a very small sample for the model to accurately learn on. The model is then used to test on the remaining 20% of the data. The sizes of training and test data cast a doubt on the accuracy of the model. Additionally, the hyperparameters of the decision tree classifier, other than maximum depth and minimum samples split are not optimized but simply kept default.

Additionally, the simplistic anthropometric data and parameters that can be gathered in a routine blood analysis are certainly useful as biomarkers but are not sufficiently detailed to be key predictors.

### Assumptions

There are several underlying assumptions of the analysis. The first of these assumptions is reliability of the data. The analysis doesn't investigate the source and circumstances under which the data was collected. Additionally, the predictors available in the data are the only source of information available, meaning all else is assumed equal. Lastly, the model of choice for the analysis is assumed to be decision tree classification rather than any other supervised learning algorithm.

## Future Direction

Although the breast cancer predictions analysis accomplishes the fundamental question posed in the beginning, there are several ways in which the analysis could be developed further. The ways in which this analysis can be advanced are as follows:

1.	Calculate likelihood of breast cancer in a new patient
2.	Evaluate feature importance derived by other parametric algorithms
3.	Assess accuracy of predictions using other models
